{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56d14076",
   "metadata": {},
   "source": [
    "# Treinamento e Teste das CNNs para classificação de LIBRAS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b705b48",
   "metadata": {},
   "source": [
    "peguei muita coisa desse site !\n",
    "https://www.datacamp.com/tutorial/cnn-tensorflow-python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014681be",
   "metadata": {},
   "source": [
    "## Importações, declaração de variáveis globais e carregamento dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51300c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importações iniciais\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np \n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.metrics import Precision, Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c90899f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#variáveis globais\n",
    "INPUT_SHAPE = (64, 64, 1)\n",
    "FILTER1_SZ = 32\n",
    "FILTER2_SZ = 64\n",
    "FILTER_SHAPE = (3, 3)\n",
    "POOL_SHAPE = (2, 2)\n",
    "FULLY_CONNECT_NUM = 128\n",
    "NUM_CLASSES = 21\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 30\n",
    "\n",
    "METRICS = metrics=['accuracy', Precision(name='precision'), Recall(name='recall')]\n",
    "\n",
    "classes = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'I', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'Y']\n",
    "\n",
    "img_size=(64, 64)\n",
    "\n",
    "class_to_idx = {c: i for i, c in enumerate(classes)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee02a49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#função auxiliar para função de carregar os dados\n",
    "def load_split(split, root):\n",
    "    imgs = []\n",
    "    labels = []\n",
    "    split_dir = os.path.join(root, split)\n",
    "    for cls in classes:\n",
    "        cls_dir = os.path.join(split_dir, cls)\n",
    "        if not os.path.isdir(cls_dir):\n",
    "            continue\n",
    "        for fname in os.listdir(cls_dir):\n",
    "            if not fname.lower().endswith(\".png\"):\n",
    "                continue\n",
    "            path = os.path.join(cls_dir, fname)\n",
    "            img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "            if img is None:\n",
    "                continue\n",
    "            img = cv2.resize(img, img_size)\n",
    "            img = img.astype(\"float32\") / 255.0\n",
    "            img = np.expand_dims(img, axis=-1)  # (H, W, 1)\n",
    "            imgs.append(img)\n",
    "            labels.append(class_to_idx[cls])\n",
    "    imgs = np.stack(imgs, axis=0)\n",
    "    labels = np.array(labels, dtype=\"int32\")\n",
    "    return imgs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce955481",
   "metadata": {},
   "outputs": [],
   "source": [
    "#função para carregar os dados\n",
    "\n",
    "def load_libras_data(raw_root=\"data_balanced\", pre_root=\"data_balanced_preprocessed\", img_size=img_size):\n",
    "    # dados brutos\n",
    "    train_imgs, train_labels_int = load_split(\"train\", raw_root)\n",
    "    test_imgs, test_labels_int = load_split(\"test\", raw_root)\n",
    "\n",
    "    # dados pré-processados\n",
    "    train_imgs_pre, _ = load_split(\"train\", pre_root)\n",
    "    test_imgs_pre, _ = load_split(\"test\", pre_root)\n",
    "    \n",
    "    # one-hot para Keras\n",
    "    num_classes = len(classes)\n",
    "    train_labels = to_categorical(train_labels_int, num_classes=num_classes)\n",
    "    test_labels = to_categorical(test_labels_int, num_classes=num_classes)\n",
    "\n",
    "    return (train_imgs, train_imgs_pre, train_labels,\n",
    "            test_imgs, test_imgs_pre, test_labels)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddbd265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# carregando dados\n",
    "(train_imgs,\n",
    " train_imgs_preprocessed,\n",
    " train_labels,\n",
    " test_imgs,\n",
    " test_imgs_preprocessed,\n",
    " test_labels) = load_libras_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6841d510",
   "metadata": {},
   "source": [
    "## Implementação da arquitetura do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158b06f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LibrasCNN(INPUT_SHAPE=INPUT_SHAPE, NUM_CLASSES=NUM_CLASSES):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(FILTER1_SZ, FILTER_SHAPE, activation='relu', input_shape=INPUT_SHAPE))\n",
    "    model.add(MaxPooling2D(POOL_SHAPE))\n",
    "    model.add(Conv2D(FILTER2_SZ, FILTER_SHAPE, activation='relu'))\n",
    "    model.add(MaxPooling2D(POOL_SHAPE))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(FULLY_CONNECT_NUM, activation='relu'))\n",
    "    model.add(Dense(NUM_CLASSES, activation='softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99fdd2f",
   "metadata": {},
   "source": [
    "## Sumário"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05385c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_model = LibrasCNN()\n",
    "non_preprocessed_model = LibrasCNN()\n",
    "\n",
    "preprocessed_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0cd9e59",
   "metadata": {},
   "source": [
    "## Treinamento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70cb2030",
   "metadata": {},
   "source": [
    "### CNN com dados sem pré-processamento em OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f455edee",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_preprocessed_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=METRICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ffb0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_history1 = preprocessed_model.fit(train_imgs, train_labels, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_data=(test_imgs, test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2360802",
   "metadata": {},
   "source": [
    "### CNN com dados pré-processados em OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052a7043",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=METRICS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c75353a",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_history2 = preprocessed_model.fit(train_imgs_preprocessed, train_labels, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_data=(test_imgs_preprocessed, test_labels))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
